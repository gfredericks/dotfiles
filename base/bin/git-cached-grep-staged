#!/usr/bin/env python3

# runs grep -P on the staged content, and uses a cache to speed up
# subsequent invocations

import hashlib
import os
import sys
import time
import io
from collections import namedtuple
import subprocess

if len(sys.argv) != 2:
    print("USAGE: {} $GREP_DASH_P_PATTERN".format(sys.argv[0]), file=sys.stderr)
    sys.exit(2)

grep_pattern = sys.argv[1]
os.environ['GREP_PATTERN'] = grep_pattern
runtime = int(time.time() * 1000)

with os.popen('git write-tree') as stream:
    root_tree_id = stream.read().rstrip()

pattern_hash = hashlib.md5((grep_pattern + "\n").encode('utf-8')).hexdigest()

cache_file = ".git-cached-grep-staged-{}".format(pattern_hash)
# Set this using:
# git config --local gfredericks.git-cached-grep-staged-cache-dir some-absolute-or-relative-path
configured_cache_dir = subprocess.run(
    ["git", "config", "--local", "--get", "gfredericks.git-cached-grep-staged-cache-dir"],
    capture_output=True
).stdout.decode("UTF-8")
if configured_cache_dir:
    cache_file = f"{configured_cache_dir.strip()}/{cache_file}"

cache_size = 1000
# Set this using:
# git config --local gfredericks.git-cached-grep-staged-cache-size 10000
configured_cache_size = subprocess.run(
    ["git", "config", "--local", "--get", "gfredericks.git-cached-grep-staged-cache-size"],
    capture_output=True
).stdout
if configured_cache_size:
    cache_size = int(configured_cache_size)



CacheEntry = namedtuple('CacheEntry', ['match_count', 'last_access_ms'])

cache = {}

# go_tree and go_blob update the cache and print lines
def go_tree(tree_id, prefix, cache_penalty):
    cache_entry = cache.get(tree_id)
    if cache_entry is None or cache_entry.match_count > 0:
        match_count_tree = 0
        lines = subprocess.run(['git','ls-tree','--full-tree','-z',tree_id], stdout=subprocess.PIPE).stdout.split(b'\0')
        for line in lines:
            if len(line) == 0:
                continue
            line = line.decode('utf-8')
            mode, obtype, rest = line.split(' ', 2)
            obid, entry = rest.split('\t', 1)
            if obtype == 'blob':
                fn = go_blob
                prefix_arg = "{}{}".format(prefix, entry)
            elif obtype == 'tree':
                fn = go_tree
                prefix_arg = "{}{}/".format(prefix, entry)
            elif obtype == 'commit':
                # this is for submodules? I guess?
                continue
            else:
                print("INVALID OBJECT TYPE IN {} {!r}".format(tree_id, obtype), file=sys.stderr)
                print("{!r}".format(line), file=sys.stderr)
                sys.exit(2)

            fn(obid, prefix_arg, cache_penalty - 1)
            match_count_tree += cache.get(obid).match_count
        cache[tree_id] = CacheEntry(match_count_tree, runtime + cache_penalty)
    else:
        cache[tree_id] = CacheEntry(cache_entry.match_count, runtime + cache_penalty)

def go_blob(blob_id, prefix, cache_penalty):
    cache_entry = cache.get(blob_id)
    if cache_entry is not None and cache_entry.match_count == 0:
        cache[blob_id] = CacheEntry(0, runtime + cache_penalty)
    else:
        script = """
        git cat-file blob {} | {{ grep -n -P "$GREP_PATTERN" || true; }}
        """.format(blob_id)
        cp = subprocess.run(["/usr/bin/env","bash","-c",script], stdout=subprocess.PIPE)
        match_count = 0
        for line in cp.stdout.decode('utf-8').split('\n'):
            if len(line) == 0:
                continue
            print("{}:{}".format(prefix, line))
            match_count += 1
        cache[blob_id] = CacheEntry(match_count, runtime + cache_penalty)

# File line format each line:
# $LAST_ACCESS $OBJECT_ID $MATCH_COUNT
def read_cache():
    if os.path.exists(cache_file):
        with open(cache_file) as f:
            for line in f:
                last_access_ms, obid, match_count = line.split(' ')
                cache[obid] = CacheEntry(int(match_count), int(last_access_ms))

def write_cache():
    items = sorted(cache.items(), key=lambda item: item[1].last_access_ms, reverse=True)
    with open(cache_file, 'w') as f:
        for obid, cache_entry in items[0:cache_size]:
            f.write("{} {} {}\n".format(
                cache_entry.last_access_ms,
                obid,
                cache_entry.match_count
            ))

read_cache()
go_tree(root_tree_id, "", 0)
write_cache()
